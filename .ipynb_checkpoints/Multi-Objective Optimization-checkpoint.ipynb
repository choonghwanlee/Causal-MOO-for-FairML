{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22433776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bc9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "compas_scores = pd.read_csv('compas/cox-violent-parsed_filt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4f4b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'sex', 'dob', 'age', 'age_cat', 'race',\n",
       "       'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count',\n",
       "       'priors_count', 'days_b_screening_arrest', 'c_jail_in', 'c_jail_out',\n",
       "       'c_days_from_compas', 'c_charge_degree', 'c_charge_desc', 'is_recid',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'violent_recid', 'is_violent_recid',\n",
       "       'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc',\n",
       "       'type_of_assessment', 'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'priors_count.1', 'event'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68232e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clean null\n",
    "compas_scores = compas_scores.dropna(subset=['race', 'age','juv_fel_count','juv_misd_count','priors_count','is_recid','c_charge_degree'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d659176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract type of crime\n",
    "compas_scores[\"type\"] = compas_scores[\"c_charge_degree\"].map(lambda x: \"fel\" if \"F\" in x else \"other\" if \"MO\" in x else \"misd\" if \"M\" in x else \"other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98118a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'African-American', 'Caucasian', 'Hispanic', 'Asian',\n",
       "       'Native American'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_scores['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #simplify race to binary case\n",
    "compas = compas_scores[compas_scores['race'].isin(['African-American','Caucasian'])]\n",
    "# compas_scores['race'] = compas_scores['race'].map(lambda x: \"African-American\" if x == \"African-American\" else \"Other\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3450d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/ff36cp25227f2f9fl6vklh440000gn/T/ipykernel_92544/4185449183.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compas['score_text'] = compas['score_text'].map(lambda x: 0 if x == \"Low\" else 1)\n"
     ]
    }
   ],
   "source": [
    "#simplify label\n",
    "compas['score_text'] = compas['score_text'].map(lambda x: 0 if x == \"Low\" else 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b68732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index \n",
    "compas = compas.reset_index().drop(columns=['index','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "041509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataframes\n",
    "\n",
    "# features \n",
    "features = compas[['juv_fel_count','juv_misd_count','priors_count','type','age']]\n",
    "\n",
    "# sensitive attribute\n",
    "sensitive = compas['race']\n",
    "\n",
    "#predicted (O)\n",
    "y = compas['score_text']\n",
    "\n",
    "#actual outcome (Y)\n",
    "ground_truth = compas['is_recid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69e344",
   "metadata": {},
   "source": [
    "## Fairness through Unawareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af1115ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logistic regression: one-hot encode type variable\n",
    "X = pd.concat([features,pd.get_dummies(features['type'])],axis=1).drop(columns='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c4df369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale/normalize values \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f774983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc7377d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actual recividism outcome for test dataset \n",
    "y_truth = ground_truth[y_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0047523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "598e1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions \n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c55f4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index \n",
    "y_pred = pd.Series(y_pred,index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fa70d79f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7438561438561438"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c324069c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336659142047282"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ccb6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(y_pred, y_truth, sensitive):\n",
    "    \n",
    "    # test dataset index for African Americans   \n",
    "    protected = sensitive[sensitive=='African-American'].index.intersection(y_truth.index)\n",
    "    # test dataset index for Caucasians\n",
    "    unprotected = sensitive[sensitive=='Caucasian'].index.intersection(y_truth.index)\n",
    "    #actual recividism outcome + model predictions for African Americans\n",
    "    y_truth_protected = y_truth[protected]\n",
    "    y_pred_protected = y_pred[protected]\n",
    "    #actual recividism outcome + model predictions for Caucasians\n",
    "    y_truth_unprotected = y_truth[unprotected]\n",
    "    y_pred_unprotected = y_pred[unprotected]\n",
    "    return y_truth_protected, y_pred_protected, y_truth_unprotected, y_pred_unprotected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "be2262d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppv_diff(y_pred, y_truth, sensitive):\n",
    "    \n",
    "    #extract relevant data\n",
    "    y_truth_protected, y_pred_protected, y_truth_unprotected, y_pred_unprotected = data_parser(y_pred, y_truth, sensitive)\n",
    "    # index for African Americans predicted to recidivate \n",
    "    p_predicted_true = y_pred_protected[y_pred_protected == 1].index\n",
    "    # portion of African Americans predicted to recidivate who actually recidivated \n",
    "    p_ppv = y_truth_protected[p_predicted_true].sum()/len(y_truth_protected[p_predicted_true])\n",
    "    # index for Caucasians predicted to recidivate\n",
    "    up_predicted_value = y_pred_unprotected[y_pred_unprotected == 1].index\n",
    "    # portion of Caucasians predicted to recidivate who actually recidivated\n",
    "    up_ppv = y_truth_unprotected[up_predicted_value].sum()/len(y_truth_unprotected[up_predicted_value])\n",
    "    \n",
    "    return abs(p_ppv-up_ppv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3f50cd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06416249726251244"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppv_diff(y_pred,y_truth, sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "81eca2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eo_diff(y_pred,y_truth,sensitive):\n",
    "    y_truth_protected, y_pred_protected, y_truth_unprotected, y_pred_unprotected = data_parser(y_pred, y_truth, sensitive)\n",
    "    total_eo_diff = 0\n",
    "    # add FNR and FPR\n",
    "    for i in range(0,2):\n",
    "        #index for African Americans who actually didn't/did't recidivated\n",
    "        p_truth_value = y_truth_protected[y_truth_protected == i].index\n",
    "        #portion of African Americans who didn't/did recidivated who were predicted to/not to \n",
    "        p_eo = (y_pred_protected[p_truth_value] == 1-i).sum()/len(y_pred_protected[p_truth_value])\n",
    "        #index for Caucasians who actually didn't/did't recidivated \n",
    "        up_truth_value = y_truth_unprotected[y_truth_unprotected == i].index\n",
    "        #portion of Caucasians who didn't/did recidivated who were predicted to/not to \n",
    "        up_eo = (y_pred_unprotected[up_truth_value] == 1-i).sum()/len(y_pred_unprotected[up_truth_value])\n",
    "        total_eo_diff+=abs(p_eo-up_eo)\n",
    "    return total_eo_diff/2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4282adf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24027512690644837"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo_diff(y_pred,y_truth,sensitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17706c59",
   "metadata": {},
   "source": [
    "## Multi-Objective Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_pred, y_true, y_outcome, sample_weights=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    \n",
    "    if np.any(y_true==0):\n",
    "        print(\"Found zeroes in y_true. MAPE undefined. Removing from set...\")\n",
    "        idx = np.where(y_true==0)\n",
    "        y_true = np.delete(y_true, idx)\n",
    "        y_pred = np.delete(y_pred, idx)\n",
    "        if type(sample_weights) != type(None):\n",
    "            sample_weights = np.array(sample_weights)\n",
    "            sample_weights = np.delete(sample_weights, idx)\n",
    "        \n",
    "    if type(sample_weights) == type(None):\n",
    "        return(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n",
    "    else:\n",
    "        sample_weights = np.array(sample_weights)\n",
    "        assert len(sample_weights) == len(y_true)\n",
    "        return(100/sum(sample_weights)*np.dot(\n",
    "                sample_weights, (np.abs((y_true - y_pred) / y_true))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca828c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticClassifier:\n",
    "    def __init__(self, loss_function=custom_loss, X=None, Y=None, sample_weights=None, \n",
    "                 beta_init=None, regularization=0.00012):\n",
    "        self.regularization = regularization\n",
    "        self.beta = None \n",
    "        self.loss_function = loss_function\n",
    "        self.sample_weights = sample_weights\n",
    "        self.beta_init = beta_init\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        x_dot_weights = np.matmul(x, self.sample_weights.transpose()) + self.bias\n",
    "        probabilities = self._sigmoid(x_dot_weights)\n",
    "        return probabilities\n",
    "    \n",
    "    def model_error(self):\n",
    "        error = self.loss_function(\n",
    "            self.predict(self.X), self.Y, sample_weights=self.sample_weights\n",
    "        )\n",
    "        return(error)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
